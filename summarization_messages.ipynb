{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import json\n",
    "import librosa\n",
    "import pytesseract\n",
    "import random\n",
    "import soundfile\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import notebook_login\n",
    "from pytesseract import Output\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, DataCollatorForSeq2Seq, AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from transformers import create_optimizer, AdamWeightDecay, TFAutoModelForSeq2SeqLM\n",
    "from transformers.keras_callbacks import KerasMetricCallback, PushToHubCallback\n",
    "from transformers.pipelines.pt_utils import KeyDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Link to Hugging Face Dataset with Channel Messages](https://huggingface.co/datasets/pszemraj/midjourney-messages-cleaned)\n",
    "\n",
    "```\n",
    "data_files = { \"train\" : [\n",
    "    'train-00000-of-00003.parquet'\n",
    "    , 'train-00001-of-00003.parquet'\n",
    "    , 'train-00002-of-00003.parquet'\n",
    "]}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "deduped_dataset = load_dataset(\"pszemraj/midjourney-messages-cleaned\", data_dir=\"deduped\", split=\"train\", verification_mode=\"no_checks\")\n",
    "# NonMatchingSplitsSizesError fixed by setting verification code to none\n",
    "# https://discuss.huggingface.co/t/nonmatchingsplitssizeserror/30033/4\n",
    "# dataset = load_dataset(\"pszemraj/midjourney-messages-cleaned\", split=\"train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'channel_id', 'text'],\n",
       "    num_rows: 14828769\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deduped_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '1090949770530521099',\n",
       " 'channel_id': '995431305066065950',\n",
       " 'text': \"A surreal photograph of a married couple floating on their backs in a lake at night, surrounded by a bed of shimmering flowers floating on the surface of the water. The couple's eyes are closed, and their bodies are limp, as if they were suspended in a state of deep sleep or death. The composition is both eerie and tranquil, with the couple's bodies forming a diagonal line across the frame, their faces illuminated by the soft glow of the moon and stars above. The flowers, in contrast, are vibrant and colorful, creating a striking visual contrast against the dark water. The photograph was taken with a Canon EOS 5D Mark IV camera and a 24-70mm f/2.8L II USM lens, set to a shutter speed of 15 seconds, ISO 1600, and an aperture of f/4. The long exposure time creates a dreamy effect, blurring the movement of the water and adding to the surreal quality of the image. The stillness of the couple, combined with the floating flowers, gives the impression of a mystical, otherworldly scene. The photograph invites the viewer to contemplate the mysteries of life and death, the beauty of nature, and the power of love and connection.\"}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(deduped_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': ['1105917785852362823'],\n",
       " 'channel_id': ['1008571023047798794'],\n",
       " 'text': ['einen gutschein mit den Angaben von und an und Betrag']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deduped_dataset.sort(\"channel_id\")[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = deduped_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = messages.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '1092432530688462918',\n",
       " 'channel_id': '989268300473192561',\n",
       " 'text': 'ultra realistic portrait, full length, woman in her forties answering the door to receive takeaway delivery, film grain, chiaroscuro, golden hour'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://huggingface.co/docs/transformers/v4.15.0/en/custom_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd031c6edeca4fba824701698c25b3fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b8d6b6c70d947998d97ebac2b6afc0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1deffdab4f5b494ebf45d3ad3d783e7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7e77c6e8a344ef398622514e6ffdf35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7cfb6131e8744efb26174580c9ec146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11863015 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_msg = messages.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_imdb[\"train\"],\n",
    "    eval_dataset=tokenized_imdb[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6da26a5b0481d39b6fe16099ce6f4dea8f8570d0d73dc88affaf7d040d2c8a3b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
